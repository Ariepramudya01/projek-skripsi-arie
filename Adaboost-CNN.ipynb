{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778c027-f716-453c-a566-4ea21445fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a820d-171a-4136-9e2d-3e4758f12599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from IPython.display import Audio\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve,  auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7219edb-c366-4504-b6d5-ca62981de01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio params\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 20.0 # duration in second\n",
    "AUDIO_LEN = int(SAMPLE_RATE * DURATION)\n",
    "\n",
    "# Spectrogram params\n",
    "N_MELS = 128 # freq axis\n",
    "N_FFT = 2048\n",
    "SPEC_WIDTH = 256 # time axis\n",
    "HOP_LEN = 512 # non-overlap region\n",
    "FMAX = SAMPLE_RATE//2 # max frequency\n",
    "\n",
    "# Ada-CNN params\n",
    "NUM_CLASSES = 1 # bonafide or spoof\n",
    "BATCH_SIZE = 32 # adjust based on your memory\n",
    "EPOCHS = 50 # adjust based on your time\n",
    "LEARNING_RATE = 0.0001 # adjust based on your model performance\n",
    "N_ESTIMATORS = 10\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1585f6e-0da3-4e1c-aa0d-d177a8e0845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membentuk path lengkap sebuah file\n",
    "def get_file_path(directory, filename):\n",
    "    return os.path.join(directory, f'{filename}.flac')\n",
    "\n",
    "# Fungsi untuk membaca dataset\n",
    "def read_dataset(protocol_path, directory):\n",
    "    \"\"\"Reads the dataset from a protocol file and returns a DataFrame.\"\"\"\n",
    "    df = pd.read_csv(protocol_path, sep=' ', header=None, names=['speaker_id', 'filename', 'system_id', 'null', 'class_name'])\n",
    "    df['filepath'] = df['filename'].apply(lambda x: get_file_path(directory, x))\n",
    "    df.drop('null', axis=1, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Fungsi untuk mengubah class_name menjadi integer\n",
    "def label_to_int(class_name):\n",
    "    if class_name == 'bonafide':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Menambahkan kolom target dan subset ke DataFrame\n",
    "def add_columns(df, subset):\n",
    "    df['target'] = df['class_name'].apply(label_to_int)\n",
    "    df['subset'] = subset\n",
    "    return df\n",
    "\n",
    "# Fungsi untuk melakukan resampling data\n",
    "def sample_per_group(df, column, frac):\n",
    "    return df.groupby(column).apply(lambda x: x.sample(frac=frac)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53869c-c267-4c8c-a6ce-5cc2cd9a3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for each dataset\n",
    "train_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.train.trn.txt'), train_dir)\n",
    "val_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.dev.trl.txt'), val_dir)\n",
    "test_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.eval.trl.txt'), test_dir)\n",
    "\n",
    "# Menambahkan kolom ke setiap DataFrame\n",
    "train_df = add_columns(train_df, 'train')\n",
    "val_df = add_columns(val_df, 'val')\n",
    "test_df = add_columns(test_df, 'test')\n",
    "\n",
    "# Mengambil 10% sampel dari setiap speaker pada setiap DataFrame\n",
    "train_df = sample_per_group(train_df, 'speaker_id', 0.1)\n",
    "val_df = sample_per_group(val_df, 'speaker_id', 0.1)\n",
    "test_df = sample_per_group(test_df, 'speaker_id', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296a1bc-f20d-4457-aefd-11aaa027a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menggabungkan ketiga dataframe menjadi satu dataframe\n",
    "data_df = pd.concat([train_df, val_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b950221-0117-4407-8efc-a393d52aceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menampilkan dataframe\n",
    "data_df.head(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1523ebb-0cc7-46cd-b302-463b770426f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat DataFrame baru untuk plot dengan hanya 'bonafide' dan 'spoof'\n",
    "plot_df = data_df[data_df['class_name'].isin(['bonafide', 'spoof'])]\n",
    "\n",
    "# Mengelompokkan data berdasarkan 'class_name' dan 'subset'\n",
    "plot_df = plot_df.groupby(['subset', 'class_name']).size().reset_index(name='counts')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(x='class_name', y='counts', hue='subset', data=plot_df)\n",
    "\n",
    "# Menambahkan nilai pada setiap bar\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.0f}'.format(height),\n",
    "            ha=\"center\") \n",
    "\n",
    "plt.title('Distribusi Data Bonafide dan Spoof Setelah Melakukan Resampling dan Pengambilan Sampel')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total keseluruhan data adalah sebanyak {len(data_df)} data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1df28e-547c-44a9-9395-b21d929f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = data_df['speaker_id'].iloc[0]\n",
    "sample_df = data_df\n",
    "\n",
    "selected_bonafide = sample_df[(sample_df['class_name'] == 'bonafide') & (sample_df['speaker_id'] == speaker_id)].iloc[0]\n",
    "selected_spoof = sample_df[(sample_df['class_name'] == 'spoof') & (sample_df['speaker_id'] == speaker_id)].iloc[0]\n",
    "\n",
    "for selected_audio in [selected_bonafide, selected_spoof]:\n",
    "    # Muat file audio\n",
    "    audio_tensor = tfio.audio.AudioIOTensor(selected_audio['filepath'])\n",
    "    audio = audio_tensor.to_tensor()\n",
    "\n",
    "    # Dapatkan sample rate\n",
    "    sample_rate = audio_tensor.rate.numpy()\n",
    "\n",
    "    # Tampilkan speaker_id, class_name dan nama file\n",
    "    print(f\"Speaker ID: {selected_audio['speaker_id']}\")\n",
    "    print(f\"Class Name: {selected_audio['class_name']}\")\n",
    "    print(f\"File: {selected_audio['filepath']}\")\n",
    "\n",
    "    # Tampilkan waveplot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(audio.numpy())\n",
    "    plt.title(f\"Waveplot for {selected_audio['class_name']}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Putar audio\n",
    "    display(Audio(audio.numpy().squeeze(), rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a22efe-3bb5-4633-a434-6fad27f185e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membaca file audio dan mengubahnya menjadi spektrogram\n",
    "def audio_to_spectrogram(filepath):\n",
    "    # Membaca file audio\n",
    "    audio = tfio.audio.AudioIOTensor(filepath)\n",
    "    \n",
    "    # Mengambil sampel audio dan mengubahnya menjadi float32\n",
    "    audio_slice = audio.to_tensor()\n",
    "    audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "    audio_tensor = tf.cast(audio_tensor, tf.float32)\n",
    "    \n",
    "    # Normalisasi audio\n",
    "    tensor = tf.math.divide(\n",
    "        tf.subtract(\n",
    "            audio_tensor, \n",
    "            tf.reduce_min(audio_tensor)\n",
    "        ), \n",
    "        tf.subtract(\n",
    "            tf.reduce_max(audio_tensor), \n",
    "            tf.reduce_min(audio_tensor)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Mengubah audio menjadi spektrogram\n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        tensor, \n",
    "        nfft=N_FFT, \n",
    "        window=N_FFT, \n",
    "        stride=HOP_LEN\n",
    "    )\n",
    "    \n",
    "    # Mengubah spektrogram menjadi skala Mel\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, \n",
    "        rate=SAMPLE_RATE, \n",
    "        mels=N_MELS, \n",
    "        fmin=0, \n",
    "        fmax=FMAX\n",
    "    )\n",
    "    \n",
    "    # Mengubah skala Mel menjadi desibel\n",
    "    mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\n",
    "    \n",
    "    # Menambahkan dimensi saluran\n",
    "    mel_spectrogram = tf.expand_dims(mel_spectrogram, axis=-1)\n",
    "    \n",
    "    # Mengubah ukuran spektrogram menjadi ukuran yang ditentukan\n",
    "    image = tf.image.resize(mel_spectrogram, [SPEC_WIDTH, N_MELS])\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Menambahkan kolom spektrogram ke DataFrame\n",
    "data_df['spectrogram'] = data_df['filepath'].apply(audio_to_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995b0c7-dfa4-4410-90c1-bfb49c164853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih spektrogram dari DataFrame\n",
    "first_spectrogram = sample_df.loc[0, 'spectrogram']\n",
    "\n",
    "# Gunakan fungsi imshow untuk menampilkan spektrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(tf.squeeze(first_spectrogram), aspect='auto', origin='lower')\n",
    "plt.title('Spectrogram')\n",
    "plt.ylabel('Frequency bin')\n",
    "plt.xlabel('Time frame')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Ukuran spektrogram adalah :\", first_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66256889-abde-477b-b291-78e385a66698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi data berdasarkan kolom 'subset'\n",
    "train_data = data_df[data_df['subset'] == 'train']\n",
    "val_data = data_df[data_df['subset'] == 'val']\n",
    "test_data = data_df[data_df['subset'] == 'test']\n",
    "\n",
    "# Mengubah list spektrogram menjadi array NumPy\n",
    "X_train = np.stack(train_data['spectrogram'].to_list())\n",
    "X_val = np.stack(val_data['spectrogram'].to_list())\n",
    "X_test = np.stack(test_data['spectrogram'].to_list())\n",
    "\n",
    "# Mengubah target menjadi array NumPy\n",
    "y_train = train_data['target'].to_numpy()\n",
    "y_val = val_data['target'].to_numpy()\n",
    "y_test = test_data['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16015ac6-7b98-4afc-b464-9183a822898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe71b80-485c-40b1-ae3c-90685433f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat model CNN\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # 1st conv layer\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 4th conv layer\n",
    "    model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Additional dense layer\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Membuat optimizer baru dengan learning rate yang diinginkan\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate = LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Membuat model\n",
    "keras_model = KerasClassifier(model=create_model((X_train.shape[1], X_train.shape[2], 1)), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Menerapkan Adaboost pada model CNN\n",
    "ada_model = AdaBoostClassifier(estimator=keras_model, n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "\n",
    "# Menampilkan ringkasan model\n",
    "ada_model.estimator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a642843-763f-4d91-a543-97a9f1c5e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model\n",
    "ada_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd5e2a-3315-4ee9-b22b-c30a564978f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat dictionary untuk mapping\n",
    "class_dict = {0: 'bonafide', 1: 'spoof'}\n",
    "\n",
    "# Melakukan prediksi pada set evaluasi\n",
    "y_test_pred = ada_model.predict(X_test)\n",
    "\n",
    "# Menghitung laporan klasifikasi\n",
    "report = classification_report(y_test, y_test_pred, target_names=class_dict.values())\n",
    "\n",
    "# Mencetak laporan\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c537793-ad70-4121-a8ef-b92dbb9e703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat DataFrame dari label sebenarnya dan label yang diprediksi\n",
    "error_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})\n",
    "\n",
    "# Menambahkan kolom 'Correct' yang menunjukkan apakah prediksi itu benar\n",
    "error_df['Correct'] = error_df['Actual'] == error_df['Predicted']\n",
    "\n",
    "# Menampilkan tabel analisis kesalahan\n",
    "error_df.head(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72424a42-d5a2-4f1e-be56-ad7d692507ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah prediksi yang benar dan salah untuk setiap kelas\n",
    "error_analysis = error_df.groupby(['Actual', 'Correct']).size().unstack(fill_value=0)\n",
    "# Membuat plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(error_analysis, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Error Analysis')\n",
    "plt.xlabel('Correct Prediction')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809020d-74c4-4213-883a-dad67f468c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Membuat plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_dict.values(), yticklabels=class_dict.values())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "\n",
    "# Menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d75335-b97c-4f3c-9985-d54cf6acba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung skor probabilitas\n",
    "y_score = ada_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Menghitung nilai-nilai ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "# Menghitung AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Membuat plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "\n",
    "# Menambahkan anotasi\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "plt.annotate('Threshold: {:.3f}'.format(optimal_threshold), xy=(fpr[optimal_idx], tpr[optimal_idx]), xytext=(fpr[optimal_idx], tpr[optimal_idx]-0.2),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc7143-b4c0-447d-943f-8e01a8e839c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan filepath untuk file pertama dan kedua\n",
    "first_filepath = '/kaggle/input/audiotesting/bonafide/LA_E_1027220.flac'\n",
    "second_filepath = '/kaggle/input/audiotesting/spoof/LA_E_1611480.flac'\n",
    "third_filepath = '/kaggle/input/audiotesting/bonafide/LA_E_3003752.flac'\n",
    "forth_filepath = '/kaggle/input/audiotesting/spoof/LA_E_2834763.flac'\n",
    "fifth_filepath = '/kaggle/input/audiotesting/bonafide/LA_E_3379393.flac'\n",
    "sixth_filepath = '/kaggle/input/audiotesting/spoof/LA_E_5932896.flac'\n",
    "seventh_filepath = '/kaggle/input/audiotesting/bonafide/LA_E_3757378.flac'\n",
    "eighth_filepath = '/kaggle/input/audiotesting/spoof/LA_E_6163791.flac'\n",
    "ninth_filepath = '/kaggle/input/audiotesting/bonafide/LA_E_4581379.flac'\n",
    "tenth_filepath = '/kaggle/input/audiotesting/spoof/LA_E_6828287.flac'\n",
    "\n",
    "# Membuat spektrogram untuk kedua file\n",
    "first_spectrogram = audio_to_spectrogram(first_filepath)\n",
    "second_spectrogram = audio_to_spectrogram(second_filepath)\n",
    "third_spectrogram = audio_to_spectrogram(third_filepath)\n",
    "forth_spectrogram = audio_to_spectrogram(forth_filepath)\n",
    "fifth_spectrogram = audio_to_spectrogram(fifth_filepath)\n",
    "sixth_spectrogram = audio_to_spectrogram(sixth_filepath)\n",
    "seventh_spectrogram = audio_to_spectrogram(seventh_filepath)\n",
    "eighth_spectrogram = audio_to_spectrogram(eighth_filepath)\n",
    "ninth_spectrogram = audio_to_spectrogram(ninth_filepath)\n",
    "tenth_spectrogram = audio_to_spectrogram(tenth_filepath)\n",
    "\n",
    "X_new = np.stack([first_spectrogram, second_spectrogram, third_spectrogram, forth_spectrogram, fifth_spectrogram, \n",
    "                  sixth_spectrogram, seventh_spectrogram, eighth_spectrogram, ninth_spectrogram, tenth_spectrogram])\n",
    "\n",
    "# Melakukan prediksi\n",
    "y_pred = ada_model.predict(X_new)\n",
    "\n",
    "# Menerapkan mapping ke prediksi\n",
    "y_pred_classes = [class_dict[i] for i in y_pred]\n",
    "\n",
    "# Mencetak hasil\n",
    "for i, (pred, pred_class) in enumerate(zip(y_pred, y_pred_classes)):\n",
    "    print(f\"File {i+1} memiliki nilai prediksi {pred} dan diklasifikasikan sebagai {pred_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
